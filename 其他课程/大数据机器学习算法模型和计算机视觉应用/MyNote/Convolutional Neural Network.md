# Convolutional Neural Network

(注：该节是本系列课程的最后一节，我们讨论一种基础且常见的神经网络：卷积神经网络)

- Previous Neural Network
- Examples

## Previous Neural Network 此前谈论的神经网络

神经网络最常见的一个应用就是图像识别，下面我们就以数字图像处理为例说明。

众所周知，数字图像转化成数据是一个三维的张量（灰度图就是二维）。在之前谈论的神经网络中，我们对输入变量进行加权求和得到第一层结果，然后数激活函数处理得到第二层结果，最后组合在一起得到预测结果。如下图所示

![Previous Neural Network](/img/Previous%20Neural%20Network.png)

但是你也发现了，这里的输入是一个向量，而数字图像是一个二维甚至三维的张量，很明显这样的神经网络是处理不了的。怎么办呢？或许有人说直接按照逻辑存储方式展开成一维的，但是这样会丢失一些图像的特征，每次处理还要筛选输入比较麻烦。这个时候就轮到 CNN 出场了。

## 1D Example 一维例子

首先我们以先前的神经网络也能处理的一维图为例说明卷积神经网络的工作原理。

顾名思义，卷积神经网络以一个**卷积核**遍历整个离散的图片，得到一个新的结果。由于是直接相乘，我们依然可以将这种处理看成前面提到的输入的线性组合。如下图所示：

![1D Convolution](/img/1D_convolution.png)

后面的处理依然是使用激活函数进行处理，使用如下的 ReLU 函数进行处理：
$$
    0,x<0\\
    x,else
$$

处理结果如下图：
![ReLU Operation](/img/ReLU_operation.png)
(这里我们为了让处理前后尺寸相同，在前后补0)

另外，常见的卷积处理可能在卷积之后的结果(After convolution)上加上一个偏移量，然后再交给激活函数处理。也就是说，一个卷积处理包括卷积核和偏移。也就是说，对于一个大小$k$的卷积核，我们的模型需要学习$k+1$个参数。这个数量和我们之前提到的权重复杂度和输入单元数量成平方关系要少多了。

好的，一维的卷积网络看起来比较简单，没有超出我们目前已知的框架，然后呢？

### 2D Example 二维例子

假设我们现在有一个二维图片的例子：
![2D_example](/img/CNN_2D_Image.png)

你可能已经想到了：一维的图片我们使用一维的卷积核，二维的话，我们直接使用二维的卷积核不就好了吗？没错，正是如此！

我们稍微按卷积核的尺寸在二维图片的外面一周补0，然后进行卷积，就可以得到一个新的图片。事实上，如果你知道**数字图像处理**的相关知识，你就会很熟悉上面的卷积操作。

### 3D Example

对于三维的例子也是一样的，我们设定一个三维的卷积核，然后在外周补0，进行三维的卷积即可。

### Convolutional Layer: Multiple Filters 多重卷积层

我们可以根据不同的卷积核对输入数据作不同的处理，其中常见的一种其他处理是**最大池层**，其每次卷积都返回区域内的最大值。另外，我们可以设定一个**步幅**，控制卷积核移动的长度以控制最大池处理后的数据尺寸，而不是每次只移动一个单元。

## Convolutional Neural Network 卷积神经网络

一个卷积神经网络一般的结构如图所示，其接受输入数据之后一般通过几个卷积+激活函数+最大池层先降低输入数据维度，然后在通过全连接层进行处理。前一个大过程叫做**特征学习**，后一个过程叫做**分类**。