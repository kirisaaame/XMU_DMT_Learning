{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本次作业中，你将动手实现课上介绍的 LU 分解算法（课件第10页），雅可比迭代（课件第21-24页）和高斯-塞德尔迭代算法（课件第30-31页），共轭梯度下降算法（课件第35-39页）。本次作业总分为100分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LU 分解算法（30分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一个高斯消元法（LU分解）的代码示例，你可以观察输出结果，并理解循环是如何工作的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# define A and b\n",
    "A = np.array([[2, 1, -1],\n",
    "        [-3, -1, 2],\n",
    "        [-2, 1, 2]], dtype='float64')\n",
    "n = A.shape[0]\n",
    "b = np.array([8, -11, -3], dtype='float64')\n",
    "\n",
    "# outplace LU decomposition\n",
    "L = np.eye(n) # diagonal of L is 1\n",
    "U = np.zeros_like(A)\n",
    "\n",
    "for i in range(n):\n",
    "  for j in range(i, n):\n",
    "    U[i, j] = A[i, j] - np.dot(L[i, :i], U[:i, j])\n",
    "  for j in range(i+1, n):\n",
    "    L[j, i] = (A[j, i] - np.dot(L[j, :i], U[:i, i])) / U[i, i]\n",
    "  print(f\"Step {i}, L = \")\n",
    "  print(L)\n",
    "  \n",
    "print(f\"Finished, L = \")\n",
    "print(L)\n",
    "print(f\"U = \")\n",
    "print(U)\n",
    "print(f\"LU = \")\n",
    "print(L @ U)\n",
    "\n",
    "# solve for x\n",
    "x = np.zeros(n)\n",
    "y = np.zeros(n)\n",
    "# Ly = b\n",
    "for i in range(n):\n",
    "  y[i] = (b[i] - np.dot(L[i, :i], y[:i])) / L[i, i]\n",
    "# Ux = y\n",
    "for i in range(n-1, -1, -1):\n",
    "  x[i] = (y[i] - np.dot(U[i, i+1:], x[i+1:])) / U[i, i]\n",
    "  \n",
    "print(f\"Solution x = \")\n",
    "print(x)\n",
    "print(f\"Check b - Ax =\")\n",
    "print(b - A @ x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要将上面的过程变成inplace的形式，这样做的好处是我们不需要为L，U，x开辟新的内存空间，而直接在A矩阵内部进行分解，并在b中输出最终的解。请参考课件和上面的示例补充代码中的空缺部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def LU(A):\n",
    "  n = A.shape[0]\n",
    "  for k in range(n-1):\n",
    "    for i in range(k+1, n):\n",
    "      A[i, k] = A[i, k] / A[k, k]\n",
    "      for j in range(k+1, n):\n",
    "        pass # TODO：your code here\n",
    "  return A\n",
    "\n",
    "def LUsolve(A, b):\n",
    "  A = LU(A)\n",
    "  n = A.shape[0]\n",
    "  for i in range(1, n):\n",
    "    pass # TODO：your code here\n",
    "  for i in range(n-1, -1, -1):\n",
    "    pass # TODO：your code here\n",
    "  return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "A = np.array([[2, 1, -1],\n",
    "        [-3, -1, 2],\n",
    "        [-2, 1, 2]], dtype='float64')\n",
    "b = np.array([8, -11, -3], dtype='float64')\n",
    "A0 = np.copy(A)\n",
    "b0 = np.copy(b)\n",
    "\n",
    "A = LU(A)\n",
    "print(f\"Finished, A = \")\n",
    "print(A)\n",
    "print(\"Upper triangular of A:\")\n",
    "print(np.triu(A))   \n",
    "print(\"Lower triangular of A:\")\n",
    "print(np.tril(A, -1) + np.eye(A.shape[0]))\n",
    "\n",
    "A = np.copy(A0)\n",
    "x = LUsolve(A, b)\n",
    "print(f\"Solution x = \")\n",
    "print(x)\n",
    "print(f\"Check b - Ax =\")\n",
    "print(b0 - A0 @ x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迭代算法（40分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们实现雅可比迭代和高斯-赛德尔迭代，注意比较二者的区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def Jacobi(A, b, max_iter=1000, tol=1e-6):\n",
    "  n = A.shape[0]\n",
    "  x = np.zeros(n)\n",
    "  x_new = np.zeros(n)\n",
    "  res = [np.linalg.norm(b - A @ x)]\n",
    "  for _ in range(max_iter):\n",
    "    # TODO: your code here\n",
    "    res.append(np.linalg.norm(b - A @ x))\n",
    "    if res[-1] < tol:\n",
    "      break\n",
    "  return x, res\n",
    "\n",
    "def GaussSeidel(A, b, max_iter=1000, tol=1e-6):\n",
    "  n = A.shape[0]\n",
    "  x = np.zeros(n)\n",
    "  res = [np.linalg.norm(b - A @ x)]\n",
    "  for _ in range(max_iter):\n",
    "    # TODO: your code here\n",
    "    res.append(np.linalg.norm(b - A @ x))\n",
    "    if res[-1] < tol:\n",
    "      break\n",
    "  return x, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果实现正确，你应该可以在下面的例子中看到GS比Jacobi更快的收敛速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "n = 1000\n",
    "A = np.random.rand(n, n)\n",
    "A = A + n*np.eye(n)\n",
    "b = np.random.rand(n) * 100\n",
    "\n",
    "x, res = Jacobi(A, b)\n",
    "x1, res1 = GaussSeidel(A, b)\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Residual')\n",
    "plt.yscale('log')\n",
    "plt.plot(res, label='Jacobi')\n",
    "plt.plot(res1, label='Gauss-Seidel')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 共轭梯度下降算法（30分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面请实现共轭梯度下降算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def ConjugateGradient(A, b, max_iter=1000, tol=1e-6):\n",
    "  n = A.shape[0]\n",
    "  x = np.zeros(n)\n",
    "  r = b - A @ x\n",
    "  p = np.copy(r)\n",
    "  res = [np.linalg.norm(r)]\n",
    "  for _ in range(max_iter):\n",
    "    # TODO: your code here\n",
    "    res.append(np.linalg.norm(r))\n",
    "    if res[-1] < tol:\n",
    "      break\n",
    "  return x, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果实现正确，你应该能在下面的例子中看到CG比GS更快的收敛速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# random generate othogonal matrix\n",
    "n = 1000\n",
    "Q, _ = np.linalg.qr(np.random.rand(n, n))\n",
    "A = Q.T @ np.diag(np.linspace(1, 100, n)) @ Q\n",
    "\n",
    "x, res = ConjugateGradient(A, b)\n",
    "x1, res1 = GaussSeidel(A, b)\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Residual')\n",
    "plt.yscale('log')\n",
    "plt.plot(res, label='Conjugate Gradient')\n",
    "plt.plot(res1, label='Gauss-Seidel')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simulate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
